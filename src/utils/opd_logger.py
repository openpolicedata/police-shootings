from datetime import datetime
import glob
from hashlib import sha1
import numpy as np
import pandas as pd
import re
import os
from typing import Optional
import warnings
from . import ois_matching
from . import agencyutils

def log(df: pd.DataFrame, 
        output_dir: str, 
        base_name: str, 
        keys: Optional[list[str]]=None, 
        add_date: bool=False, 
        only_diffs: bool=False):
    """Log cases to file

    Parameters
    ----------
    df : pd.DataFrame
        Table of cases to log
    output_dir : str
        Output directory to save any output file and where previous log files are located
    base_name : str
        Base filename. Today's date will be appended to it if add_date is True
    keys : Optional[list[str]], optional
        Keys to used when finding duplicates, by default None
    add_date : bool, optional
        Whether to append today's date to base_name, by default False
    only_diffs : bool, optional
        Whether to save only differences, by default False
    """
    keys = keys if keys else df.columns
    output_name = os.path.join(output_dir, base_name)
    search = output_name+"_*.csv"
    if add_date:
        output_name+="_"+datetime.now().strftime('%Y%m%d')
    output_name += '.csv'

    if only_diffs:
        old_files = glob.glob(search)
        for f in old_files:
            if len(df)==0:
                break
            df_old = pd.read_csv(f, keep_default_na=False, na_values={'',np.nan})
            def convert_to_int(x):
                if isinstance(x,str) and re.search(r'^[0-9\.]+$', x):
                    try:
                        if float(x)==int(float(x)):
                            x = int(float(x))
                    except (ValueError, OverflowError):
                        pass
                return x
            df_old = df_old.apply(lambda x: x.apply(convert_to_int))

            date_cols_added = []
            keys_use = keys.copy()
            for k in [x for x in keys if "DATE" in x.upper()]:
                if k in df_old and k in df:
                    date_cols_added.append(k+"_TMP")
                    keys_use[[j for j,m in enumerate(keys_use) if m==k][0]] = date_cols_added[-1]
                    # Format dates to ensure data types match
                    try:
                        df[date_cols_added[-1]] = pd.to_datetime(df[k], format='ISO8601', utc=True).dt.strftime('%Y%m%d_%H%M%S')
                    except:
                        df[date_cols_added[-1]] = pd.to_datetime(df[k].dt.to_timestamp(), format='ISO8601', utc=True).dt.strftime('%Y%m%d_%H%M%S')
                    df_old[date_cols_added[-1]] = pd.to_datetime(df_old[k], format='ISO8601', utc=True).dt.strftime('%Y%m%d_%H%M%S')

            with warnings.catch_warnings():
                # Ignore warning about all-NA columns
                warnings.simplefilter(action='ignore', category=FutureWarning)
                df_combo = pd.concat([df_old, df], ignore_index=True)
            df_combo = df_combo.apply(lambda x: x.apply(lambda y: str(y) if isinstance(y,dict) else y))
            df_combo = df_combo.drop_duplicates(subset=[k for k in keys_use if k in df_combo])
            df = df_combo.loc[len(df_old):].drop(columns=date_cols_added)

    if len(df)==0:
        return

    if os.path.exists(output_name):
        df_out = pd.concat([pd.read_csv(output_name, keep_default_na=False, na_values={'',np.nan}), df], ignore_index=True)
    else:
        df_out = df.copy()

    df_out.to_csv(output_name, index=False)

def generate_general_output_data(df_save:pd.DataFrame, addr_col: str, name_col: str):
    """Create a table with general columns specific to all agencies containing cases that may not already be in MPV

    Parameters
    ----------
    df_save : pd.DataFrame
        Table of specific data generated by generate_agency_output_data
    addr_col : str
        Address column in OPD data
    name_col : str
        Name column in OPD data

    Returns
    -------
    pd.DataFrame
        Table of cases to save
    """

    opd_race_col = ois_matching.get_race_col(df_save)
    opd_gender_col = ois_matching.get_gender_col(df_save)
    opd_age_col = ois_matching.get_age_col(df_save)
    cols = ['OPD ID', 'type', 'known_fatal']
    for c in df_save.columns:
        if c.startswith("MPV"):
            cols.append(c)

    df_global = df_save[cols].copy()
    df_global["OPD Date"] = df_save[ois_matching.date_col]
    df_global["OPD Agency"] = df_save['Agency']

    if name_col  in df_save:
        df_global["OPD Name"] = df_save[name_col]
    if opd_race_col  in df_save:
        df_global["OPD Race"] = df_save[opd_race_col]
    if opd_gender_col in df_save:
        df_global["OPD Gender"] = df_save[opd_gender_col]
    if opd_age_col  in df_save:
        df_global["OPD Age"] = df_save[opd_age_col]
    if addr_col:
        df_global["OPD Address"] = df_save[addr_col]
    return df_global

def generate_agency_output_data(df_mpv_agency: pd.DataFrame, 
                                df_opd: pd.DataFrame, 
                                mpv_addr_col: str, 
                                addr_col: str, 
                                name_col: str, 
                                log_demo_diffs: bool, 
                                subject_demo_correction: dict, 
                                log_age_diffs: bool, 
                                match_with_age_diff: dict, 
                                agency: str, 
                                known_fatal: bool):
    """Create a table with columns specific to this agency containing cases that may not already be in MPV

    Parameters
    ----------
    df_mpv_agency : pd.DataFrame
        Table of MPV data for agency corresponding to df_opd
    df_opd : pd.DataFrame
        OPD table to match with MPV data
    mpv_addr_col : str
        Address column in MPV data
    addr_col : str
        Address column in OPD data
    name_col : str
        Name column in OPD data
    log_demo_diffs : bool
        Whether or not to log potential race/gender differences between OPD and MPV
    subject_demo_correction : dict
        Dictionary mapping MPV rows to OPD rows for the same case but which have race and/or gender differences
    log_age_diffs : bool
        Whether or not to log potential age differences between OPD and MPV
    match_with_age_diff : dict
        Dictionary mapping MPV rows to OPD rows for the same case but which have age differences
    agency : str
        Name of agency corresponding to df_opd
    known_fatal : bool
        Whether or not data indicated whether the officer-involved shooting or use of force was fatal

    Returns
    -------
    pd.DataFrame
        Table of cases to save
    list[str]
        List of column names to use when searching for duplicates in previously saved data
    """
    
    df_opd = df_opd.copy()  # Create copy to avoid pandas warnings about setting on a copy

    mpv_race_col = ois_matching.get_race_col(df_mpv_agency)
    mpv_gender_col = ois_matching.get_gender_col(df_mpv_agency)
    mpv_age_col = ois_matching.get_age_col(df_mpv_agency)
    opd_race_col = ois_matching.get_race_col(df_opd)
    opd_gender_col = ois_matching.get_gender_col(df_opd)
    opd_age_col = ois_matching.get_age_col(df_opd)

    df_save = []
    keys = []
    if len(df_opd)>0:
        df_opd['type'] = 'Unmatched'
        df_opd['OPD ID'] = df_opd.apply(
            lambda x: ''.join(x.astype(str)),axis=1).apply(lambda value: sha1(str(value).encode('utf-8')).hexdigest()[:10]
            )
        df_save.append(df_opd)

    if log_demo_diffs and len(subject_demo_correction)>0:
        df = pd.DataFrame(subject_demo_correction).transpose()
        df['OPD ID'] = df_opd.apply(
            lambda x: ''.join(x.astype(str)),axis=1).apply(lambda value: sha1(str(value).encode('utf-8')).hexdigest()
            )
        df['type'] = 'Demo Correction?'
        # Create hash of MPV row
        df['MPV Hash'] = df_mpv_agency.loc[df.index].apply(
            lambda x: ''.join(x.astype(str)),axis=1).apply(lambda value: sha1(str(value).encode('utf-8')).hexdigest()
            )

        df["MPV Row"] = df.index
        df["MPV ID"] = df_mpv_agency.loc[df.index]['mpv_id']
        df["MPV DATE"] = df_mpv_agency.loc[df.index][ois_matching.date_col]
        df["MPV RACE"] = df_mpv_agency.loc[df.index][mpv_race_col]
        df["MPV GENDER"] = df_mpv_agency.loc[df.index][mpv_gender_col]
        df["MPV AGE"] = df_mpv_agency.loc[df.index][mpv_age_col]
        df["MPV AGENCY"] = df_mpv_agency.loc[df.index][ois_matching.agency_col]
        df["MPV ADDRESS"] = df_mpv_agency.loc[df.index][mpv_addr_col]
        df_save.append(df)
    
    if log_age_diffs and len(match_with_age_diff)>0:
        df = pd.DataFrame(match_with_age_diff).transpose()
        df['OPD ID'] = df_opd.apply(
            lambda x: ''.join(x.astype(str)),axis=1).apply(lambda value: sha1(str(value).encode('utf-8')).hexdigest()
            )
        df['type'] = 'Age Difference'
        # Create hash of MPV row
        df['MPV Hash'] = df_mpv_agency.loc[df.index].apply(
            lambda x: ''.join(x.astype(str)),axis=1).apply(lambda value: sha1(str(value).encode('utf-8')).hexdigest()
            )

        df["MPV Row"] = df.index
        df["MPV ID"] = df_mpv_agency.loc[df.index]['mpv_id']
        df["MPV DATE"] = df_mpv_agency.loc[df.index][ois_matching.date_col]
        df["MPV RACE"] = df_mpv_agency.loc[df.index][mpv_race_col]
        df["MPV GENDER"] = df_mpv_agency.loc[df.index][mpv_gender_col]
        df["MPV AGE"] = df_mpv_agency.loc[df.index][mpv_age_col]
        df["MPV AGENCY"] = df_mpv_agency.loc[df.index][ois_matching.agency_col]
        df["MPV ADDRESS"] = df_mpv_agency.loc[df.index][mpv_addr_col]
        df_save.append(df)

    if len(df_save)>0:
        df_save = pd.concat(df_save, ignore_index=True)
        df_save['Agency'] = agency
        df_save['known_fatal'] = known_fatal

        keys = ["MPV ID", 'type', 'known_fatal', 'Agency', ois_matching.date_col]
        if name_col in df_save:
            keys.append(name_col)
        if opd_race_col in df_save:
            keys.append(opd_race_col)
        if opd_gender_col in df_save:
            keys.append(opd_gender_col)
        if opd_age_col in df_save:
            keys.append(opd_age_col)
        if addr_col:
            keys.append(addr_col)

        new_cols = ['type', 'known_fatal', 'Agency']
        mpv_cols = [x for x in df_save.columns if x.lower().startswith("mpv")]
        new_cols.extend(mpv_cols)
        new_cols.extend([k for k in keys if k not in new_cols and k in df_save])
        new_cols.extend([x for x in df_save.columns if x not in new_cols])
        df_save = df_save[new_cols]

    return df_save, keys

def log_possible_matches(output_dir, base_name, df_global, df_all, df_mpv, 
                         location, state,
                         mpv_addr_col, addr_col, add_date=True):
    """Log potential matches for each case to help users evaluate whether identified cases are actually not in the database

    Parameters
    ----------
    output_dir : str
        Output directory to save output file
    base_name : str
        Base filename. Today's date will be appended to it if add_date is True
    df_global : pd.DataFrame
        Table of global details for cases to log
    df_all : pd.DataFrame
        Table of all details for cases to log
    df_mpv : pd.DataFrame
        Table of MPV data
    location: str
        Location of agency
    state: str
        State of agency
    mpv_addr_col: str
        Address column in MPV data
    addr_col: str
        Address column in OPD data
    add_date : bool, optional
        Whether to append today's date to base_name, by default False
    """

    output_name = os.path.join(output_dir, base_name)
    if add_date:
        output_name+="_"+datetime.now().strftime('%Y%m%d')
    output_name+='.txt'

    df_mpv = df_mpv.rename(columns={mpv_addr_col:'ADDRESS'})

    if addr_col:
        df_all = df_all.rename(columns={addr_col:'ADDRESS'})

    if not (is_period:=isinstance(df_all['DATE'].dtype, pd.PeriodDtype)):
        df_all['DATE'] = pd.to_datetime(df_all['DATE'])

    assert len(df_global) == len(df_all)

    state_abbrev = agencyutils.state_abbrev(state)
    out_cols = ['DATE', 'SUBJECT_NAME','ADDRESS','SUBJECT_RE_GROUP','SUBJECT_GENDER','SUBJECT_AGE','AGENCY','State','ZIP_CODE']
    for k in range(len(df_global)):
        row = df_global.iloc[k]
        df_res = df_all.iloc[k].copy()
        
        df_res['State'] = state_abbrev
        df_res['AGENCY'] = location

        df_mpv_cur = df_mpv[df_mpv['AGENCY'].str.lower().str.contains(location.lower())]

        assert len(df_mpv_cur)>0

        if 'SUBJECT_AGE' not in df_res and 'SUBJECT_AGE_RANGE' in df_res:
            df_res = df_res.rename(index={'SUBJECT_AGE_RANGE','SUBJECT_AGE'})

        if is_period:
            matches = df_mpv_cur['DATE'].apply(lambda x: df_res['DATE'].start_time <= x <= df_res['DATE'].end_time)
            df_comp = pd.concat([df_res.to_frame().T, df_mpv_cur[matches]])
        else:
            if df_res['DATE'].tz:
                df_res['DATE'] = df_res['DATE'].tz_convert(None)
            off_by_month = (df_mpv_cur['DATE'].dt.year==df_res['DATE'].year) & \
                    (df_mpv_cur['DATE'].dt.day==df_res['DATE'].day) & \
                    ((df_mpv_cur['DATE'].dt.month-df_res['DATE'].month).abs()<=1)
            date_matches = (df_mpv_cur['DATE'] - df_res['DATE']).abs() <'3d'

            matches = off_by_month | date_matches
            df_comp = pd.concat([df_res.to_frame().T, df_mpv_cur[matches]])

            df_mpv_state = df_mpv[df_mpv['State'].str.contains(state_abbrev)]
            df_mpv_state = df_mpv_state.drop(index=df_mpv_cur.index, errors='ignore')
            off_by_month = (df_mpv_state['DATE'].dt.year==df_res['DATE'].year) & \
                    (df_mpv_state['DATE'].dt.day==df_res['DATE'].day) & \
                    ((df_mpv_state['DATE'].dt.month-df_res['DATE'].month).abs()<=1)
            date_matches = (df_mpv_state['DATE'] - df_res['DATE']).abs() <'3d'

            matches_state = off_by_month | date_matches
            df_comp = pd.concat([df_comp, df_mpv_state[matches_state]])

        index = df_comp.index.tolist()
        index[0] = 'OPD'
        df_comp.index = index

        if not os.path.exists(output_name):
            with open(output_name, 'w') as f:
                f.write('Tables in this file are best viewed with an editor that will not automatically wrap text.\n')
                f.write('Notepad or Notepad++ are recommended.\n')
                f.write('If text is wrapped in Notepad or Notepad++, go to View > Word Wrap.\n\n')
                f.write('If looking for a specific case, it is recommended to search using the OPD ID.\n\n\n')

        with open(output_name, 'a') as f:
            # to_markdown throws an error if pd.NA is used as NaN instead of np.nan
            f.write('Details of Potential Update:\n\n')
            f.write('Global Details:\n')
            row.to_frame().T.to_markdown(f, index=False)

            f.write('\n\nAll Details:\n')
            df_res.to_frame().T.to_markdown(f, index=False)

            f.write('\n\nPossible Matches:\n')
            df_comp[out_cols].astype('O').fillna(np.nan).T.to_markdown(f)
            f.write('\n\n----------------------------------------------------------------------------------------------------------------------------')
            f.write('\n----------------------------------------------------------------------------------------------------------------------------')
            f.write('\n----------------------------------------------------------------------------------------------------------------------------\n\n')